version: 0.1.1
title: A Simple Implementation and Demonstration of Gradient Boosting
maintainer: David Shaub
description: |-
  A basic, clear implementation of tree-based gradient boosting
  designed to illustrate the core operation of boosting models. Tuning
  parameters (such as stochastic subsampling, modified learning rate, or
  regularization) are not implemented. The only adjustable parameter is the
  number of training rounds. If you are looking for a high performance boosting
  implementation with tuning parameters, consider the 'xgboost' package.
date_publication: '2016-04-19'
bug_reports: https://github.com/dashaub/DidacticBoost/issues
url: ''
url_cran: https://CRAN.R-project.org/package=DidacticBoost
url_git: https://github.com/dashaub/DidacticBoost
