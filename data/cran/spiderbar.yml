version: 0.2.2
title: Parse and Test Robots Exclusion Protocol Files and Rules
maintainer: Bob Rudis
description: |-
  The 'Robots Exclusion Protocol' <https://www.robotstxt.org/orig.html> documents
  a set of standards for allowing or excluding robot/spider crawling of different areas of
  site content. Tools are provided which wrap The 'rep-cpp' <https://github.com/seomoz/rep-cpp>
  C++ library for processing these 'robots.txt' files.
date_publication: '2019-08-19'
bug_reports: https://gitlab.com/hrbrmstr/spiderbar/issues
url: ''
url_cran: https://CRAN.R-project.org/package=spiderbar
url_git: https://gitlab.com/hrbrmstr/spiderbar
