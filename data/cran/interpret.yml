version: 0.1.24
title: |-
  Fit Interpretable Machine Learning Models and Explain Blackbox
  Machine Learning
maintainer: Rich Caruana
description: Package for training interpretable machine learning models and explaining
  blackbox systems. Historically, the most interpretable machine learning models were
  not very accurate, and the most accurate models were not very interpretable. Microsoft
  Research has developed an algorithm called the Explainable Boosting Machine (EBM)
  which has both high accuracy and interpretability. EBM uses machine learning techniques
  like bagging and boosting to breathe new life into traditional GAMs (Generalized
  Additive Models). This makes them as accurate as random forests and gradient boosted
  trees, and also enhances their intelligibility and editability. Details on the EBM
  algorithm can be found in the paper by Rich Caruana, Yin Lou, Johannes Gehrke, Paul
  Koch, Marc Sturm, and Noemie Elhadad (2015, <doi:10.1145/2783258.2788613>).
date_publication: '2019-12-12'
bug_reports: https://github.com/interpretml/interpret/issues
url: ''
url_cran: https://CRAN.R-project.org/package=interpret
url_git: https://github.com/interpretml/interpret
