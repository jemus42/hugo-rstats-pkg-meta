version: 0.3.4
title: Create Validation Tests for Automated Content Analysis
maintainer: Chung-hong Chan
description: Intended to create standard human-in-the-loop validity tests for typical
  automated content analysis such as topic modeling and dictionary-based methods.
  This package offers a standard workflow with functions to prepare, administer and
  evaluate a human-in-the-loop validity test. This package provides functions for
  validating topic models using word intrusion and Topic intrusion tests, as described
  in Chang et al. (2009) <https://papers.nips.cc/paper/3700-reading-tea-leaves-how-humans-interpret-topic-models>.
  This package also provides functions for generating gold-standard data which are
  useful for validating dictionary-based methods. The default settings of all generated
  tests match those suggested in Chang et al. (2009) and Song et al. (2020) <doi:10.1080/10584609.2020.1723752>.
date_publication: '2020-03-21'
bug_reports: https://github.com/chainsawriot/oolong/issues
url: ''
url_cran: https://CRAN.R-project.org/package=oolong
url_git: https://github.com/chainsawriot/oolong
